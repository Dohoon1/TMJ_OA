import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import random
import torch # set_seedë¥¼ ìœ„í•´ í•„ìš”

from sklearn.model_selection import StratifiedKFold
from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, roc_auc_score
from imblearn.over_sampling import SMOTE

# --- 0. ì‹œë“œ ê³ ì • ---

def set_seed(seed=42):

    torch.manual_seed(seed)

    torch.cuda.manual_seed(seed)

    torch.cuda.manual_seed_all(seed)  # if using multi-GPU

    np.random.seed(seed)

    random.seed(seed)

    torch.backends.cudnn.deterministic = True  # for reproducibility

    torch.backends.cudnn.benchmark = False



set_seed(42)



# --- 1. ë°ì´í„° ë¡œë”© ---

xlsx_path = '/content/TMJ_OA_MRI_data.xlsx'

df = pd.read_excel(xlsx_path).dropna()

df.rename(columns={'PA_TMJ_OA': 'PR_TMJ_OA'}, inplace=True)

df = df.drop(columns=['ID', 'Pain side'])



target = 'MRI_TMJ_OA'

y = df[target].values



# --- 2. ëª¨ë¸ë³„ ë³€ìˆ˜ ë¦¬ìŠ¤íŠ¸ ì •ì˜ ---

features_model1 = [

    'Sex', 'Age', 'VAS', 'Symptom duration', 'TMJ noise', 

    'Muscle stiffness', 'Locking', 'Bruxism'

] # Clinical only (8ê°œ)



features_model2 = [

    'MRI_TMJ_ADD', 'PR_TMJ_OA', 'NaMx_Discrepancy', 'MxMn_Discrepancy'

] # Imaging only (4ê°œ)


single_features_model = [

    'PR_TMJ_OA'

] 

features_model3 = features_model1 + features_model2 # Combined (12ê°œ)



# ì‹¤í–‰í•  ëª¨ë¸ ë”•ì…”ë„ˆë¦¬

model_feature_sets = {

    "Model 1 (Clinical Variables only)": features_model1,

    "Model 2 (Imaging Variables only)": features_model2,

    "Model 3 (Combined Variables)": features_model3
    
    #"Single Model (PR_TMJ_OA)": single_features_model
}

def calculate_ci(y_true, y_prob, n_bootstraps=1000, alpha=0.95):
    stats = []
    if len(y_true) < 5: return 0.0, 0.0 # ì˜ˆì™¸ ì²˜ë¦¬
    
    for i in range(n_bootstraps):
        y_true_boot, y_prob_boot = resample(y_true, y_prob, random_state=i)
        if len(np.unique(y_true_boot)) < 2: continue
        stats.append(roc_auc_score(y_true_boot, y_prob_boot))
    
    if not stats: return 0.0, 0.0
    lower = np.percentile(stats, ((1.0 - alpha) / 2.0) * 100)
    upper = np.percentile(stats, (alpha + (1.0 - alpha) / 2.0) * 100)
    return lower, upper

import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve, auc

def plot_mean_roc_with_std(tprs, aucs, model_name, ax=None, color='blue'):
    """
    ì—¬ëŸ¬ Foldì˜ ROC Curve ê²°ê³¼ë¥¼ ë°›ì•„ í‰ê·  ê³¡ì„ ê³¼ í‘œì¤€í¸ì°¨ ì˜ì—­ì„ ê·¸ë¦¬ëŠ” í•¨ìˆ˜
    
    Args:
        tprs (list): ê° Foldì˜ ë³´ê°„ëœ TPR ë¦¬ìŠ¤íŠ¸ (np.interpë¡œ ìƒì„±)
        aucs (list): ê° Foldì˜ AUROC ì ìˆ˜ ë¦¬ìŠ¤íŠ¸
        model_name (str): ë²”ë¡€ì— í‘œì‹œí•  ëª¨ë¸ ì´ë¦„
        ax (matplotlib.axes): ê·¸ë¦¼ì„ ê·¸ë¦´ ì¶• (ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±)
        color (str): ê·¸ë˜í”„ ìƒ‰ìƒ
    """
    if ax is None:
        fig, ax = plt.subplots(figsize=(8, 6))
    
    # 1. ê¸°ì¤€ FPR ì¶• ìƒì„± (0ë¶€í„° 1ê¹Œì§€ 100ê°œ êµ¬ê°„)
    mean_fpr = np.linspace(0, 1, 100)
    
    # 2. í‰ê·  TPRê³¼ í‘œì¤€í¸ì°¨ ê³„ì‚°
    mean_tpr = np.mean(tprs, axis=0)
    mean_tpr[-1] = 1.0 # ê·¸ë˜í”„ ëì ì„ (1,1)ë¡œ ê³ ì •
    std_tpr = np.std(tprs, axis=0)
    
    # 3. í‰ê·  AUROCì™€ í‘œì¤€í¸ì°¨ ê³„ì‚°
    mean_auc = np.mean(aucs)
    std_auc = np.std(aucs)
    
    # 4. í‰ê·  ROC ê³¡ì„  ê·¸ë¦¬ê¸°
    ax.plot(mean_fpr, mean_tpr, color=color,
            label=f'{model_name} (AUC = {mean_auc:.3f} $\pm$ {std_auc:.3f})',
            lw=2, alpha=.8)
    
    # 5. í‘œì¤€í¸ì°¨ ì˜ì—­(ìŒì˜) ê·¸ë¦¬ê¸° (Mean Â± 1 Std)
    tprs_upper = np.minimum(mean_tpr + std_tpr, 1) # 1.0ì„ ë„˜ì§€ ì•Šë„ë¡
    tprs_lower = np.maximum(mean_tpr - std_tpr, 0) # 0.0ë³´ë‹¤ ì‘ì§€ ì•Šë„ë¡
    ax.fill_between(mean_fpr, tprs_lower, tprs_upper, color=color, alpha=0.2,
                    label=r'$\pm$ std. dev.')
    
    # 6. ëœë¤ ì¶”ì¸¡ì„  (ëŒ€ê°ì„ )
    ax.plot([0, 1], [0, 1], linestyle='--', lw=2, color='black', alpha=.6)
    
    # 7. ê·¸ë˜í”„ ê¾¸ë¯¸ê¸°
    ax.set_xlim([-0.05, 1.05])
    ax.set_ylim([-0.05, 1.05])
    ax.set_xlabel('False Positive Rate', fontsize=12)
    ax.set_ylabel('True Positive Rate', fontsize=12)
    ax.set_title('Receiver Operating Characteristic', fontsize=14)
    ax.legend(loc="lower right")
    ax.grid(alpha=0.3)
    
    return ax

tprs = []
aucs = []
mean_fpr = np.linspace(0, 1, 100)

# --- 3. K-Fold CV ì„¤ì • ---

K = 5

skf = StratifiedKFold(n_splits=K, shuffle=True, random_state=42)



# --- 4. ëª¨ë¸ë³„ K-Fold CV ì‹¤í–‰ ë£¨í”„ ---

for model_name, current_features in model_feature_sets.items():

    

    print("\n" + "=" * 60)

    print(f"ğŸš€ [Testing] {model_name}")

    print(f"   > Features ({len(current_features)}): {', '.join(current_features)}")

    print("=" * 60)



    # í˜„ì¬ ëª¨ë¸ì˜ X ë°ì´í„° ì •ì˜

    X = df[current_features].values



    # ê° í´ë“œì˜ ì„±ëŠ¥ ì§€í‘œë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸

    fold_accuracy = []

    fold_auroc = []

    fold_sensitivity = []

    fold_specificity = []
    
    fold_auroc_ci = []

    fold_f1 = []



    for fold_idx, (train_idx, test_idx) in enumerate(skf.split(X, y)):

        

        # 1. K-Fold ë°ì´í„° ë¶„í• 

        X_train, X_test = X[train_idx], X[test_idx]

        y_train, y_test = y[train_idx], y[test_idx]



        # 2. (ì¤‘ìš”!) SMOTE: í›ˆë ¨ í´ë“œ(X_train)ì—ë§Œ ì ìš©

        # (í›ˆë ¨ ë°ì´í„°ê°€ ë¹„ì–´ìˆì§€ ì•Šê³ , í´ë˜ìŠ¤ê°€ 2ê°œ ì´ìƒì¼ ë•Œë§Œ SMOTE)

        if len(X_train) > 0 and len(np.unique(y_train)) > 1:

            smote = SMOTE(random_state=42)

            X_train_res, y_train_res = smote.fit_resample(X_train, y_train)

        else:

            X_train_res, y_train_res = X_train, y_train



        # 3. ëª¨ë¸ í›ˆë ¨ (max_depth=3ëŠ” ë…¼ë¬¸ê³¼ ë™ì¼í•˜ê²Œ ê³ ì •)

        clf = DecisionTreeClassifier(max_depth=3, random_state=42)

        clf.fit(X_train_res, y_train_res)



        # 4. í…ŒìŠ¤íŠ¸ í´ë“œë¡œ í‰ê°€

        y_pred_proba = clf.predict_proba(X_test)[:, 1]

        y_pred = (y_pred_proba > 0.5).astype(int)



        # 5. ì„±ëŠ¥ ì§€í‘œ ê³„ì‚°

        cm = confusion_matrix(y_test, y_pred)

        TN, FP, FN, TP = cm.ravel()



        sensitivity = TP / (TP + FN) if (TP + FN) > 0 else 0

        specificity = TN / (TN + FP) if (TN + FP) > 0 else 0

        f1 = f1_score(y_test, y_pred)

        accuracy = accuracy_score(y_test, y_pred)

        

        # (í…ŒìŠ¤íŠ¸ í´ë“œì— í´ë˜ìŠ¤ê°€ í•˜ë‚˜ë§Œ ìˆì–´ë„ AUROC ê³„ì‚°ì´ ì•ˆë¨)

        # AUROC ë° CI ê³„ì‚°
        if len(np.unique(y_test)) > 1:
            auroc = roc_auc_score(y_test, y_pred_proba)
            ci_low, ci_high = calculate_ci(y_test, y_pred_proba)
            
            # [ì‹œê°í™”ìš©] ROC Curve ë°ì´í„° ìˆ˜ì§‘
            fpr, tpr, _ = roc_curve(y_test, y_pred_proba)
            interp_tpr = np.interp(mean_fpr, fpr, tpr)
            interp_tpr[0] = 0.0
            tprs.append(interp_tpr)

        else:

            auroc = np.nan # ê³„ì‚° ë¶ˆê°€ëŠ¥ì‹œ NaN ì²˜ë¦¬



        # 6. ì§€í‘œ ì €ì¥

        fold_accuracy.append(accuracy)

        fold_auroc.append(auroc)

        fold_sensitivity.append(sensitivity)

        fold_specificity.append(specificity)


        fold_f1.append(f1)

        print(f"  > Fold {fold_idx + 1}/{K}... AUROC: {auroc:.4f} (95% CI: {ci_low:.3f}-{ci_high:.3f}), Accuracy: {accuracy:.4f}")



    # --- 5. ëª¨ë¸ë³„ ìµœì¢… ê²°ê³¼ ë³´ê³  (Mean Â± Std) ---

    print("-" * 60)

    print(f"ğŸ“Š [Result] {model_name} (K-Fold CV)")

    # np.nanmean/np.nanstdëŠ” NaN ê°’ì„ ë¬´ì‹œí•˜ê³  ê³„ì‚°

    print(f"AUROC:     {np.nanmean(fold_auroc):.4f} Â± {np.nanstd(fold_auroc):.4f}")

    print(f"Accuracy:  {np.mean(fold_accuracy):.4f} Â± {np.std(fold_accuracy):.4f}")

    print(f"Sensitivity: {np.mean(fold_sensitivity):.4f} Â± {np.std(fold_sensitivity):.4f}")

    print(f"Specificity: {np.mean(fold_specificity):.4f} Â± {np.std(fold_specificity):.4f}")

    print(f"F1 Score:    {np.mean(fold_f1):.4f} Â± {np.std(fold_f1):.4f}")

    print("=" * 60)

    # --- 6. ê·¸ë˜í”„ ê·¸ë¦¬ê¸° (Mean ROC with Std) ---
    # ìœ íš¨í•œ AUROC ê°’ë§Œ í•„í„°ë§ (NaN ì œê±°)
    valid_aucs = [auc for auc in fold_auroc if not np.isnan(auc)]
    
    if len(tprs) > 0:
        plt.figure(figsize=(8, 6))
        plot_mean_roc_with_std(tprs, valid_aucs, model_name, color='blue')
        plt.show()
    else:
        print("ROC Curveë¥¼ ê·¸ë¦´ ìˆ˜ ìˆëŠ” ë°ì´í„°ê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
