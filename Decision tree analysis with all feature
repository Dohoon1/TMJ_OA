import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from scipy.cluster.hierarchy import linkage, dendrogram
import networkx as nx
import plotly.graph_objects as go

from sklearn.decomposition import PCA
from mpl_toolkits.mplot3d import Axes3D
from sklearn.manifold import MDS
from scipy.spatial.distance import pdist, squareform
import plotly.io as pio

from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
from imblearn.over_sampling import SMOTE
from sklearn.tree import plot_tree

xlsx_path = '/content/TMJ_OA_MRI_data.xlsx' 

df = pd.read_excel(xlsx_path).dropna()
df.rename(columns={'PA_TMJ_OA': 'PR_TMJ_OA'}, inplace=True)
df = df.drop(columns=['ID', 'Pain side'])

# Seed
def set_seed(seed=42):
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)  # if using multi-GPU
    np.random.seed(seed)
    random.seed(seed)
    torch.backends.cudnn.deterministic = True  # for reproducibility
    torch.backends.cudnn.benchmark = False

set_seed(42)

features = [ 'Sex', 'Age',	'VAS', 'Symptom duration', 'TMJ noise',	'Muscle stiffness',	'Locking',	'Bruxism', 'MRI_TMJ_ADD',	'PR_TMJ_OA', 'NaMx_Discrepancy', 'MxMn_Discrepancy']
target = ['MRI_TMJ_OA']

# 독립변수와 종속변수 설정 / pain side도 feature로 사용하고 싶다면 아래에서 'Pain side' 제거하고 위의 feature 리스트에 'Pain side' 추가
X = df.drop(columns=['MRI_TMJ_OA']).values
y = df['MRI_TMJ_OA'].values

# Data splitting
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# SMOTE 
smote = SMOTE(random_state=42)
X_train_res, y_train_res = smote.fit_resample(X_train, y_train)

# Decision Tree with (max_depth=3)
clf = DecisionTreeClassifier(max_depth=3, random_state=42)
clf.fit(X_train_res, y_train_res)

# Evaluation with test data
y_pred = clf.predict(X_test)
print("Test Accuracy:", clf.score(X_test, y_test))

plt.figure(figsize=(12, 8))
plot_tree(
    clf,
    feature_names=features,         
    class_names=['No_OA', 'OA'],    
    filled=True,                    
    rounded=True,                   
    impurity=True,                
    proportion=False,               
    fontsize=10,                    
    precision=3,                  
    label='all'                     
)
plt.title("Decision Tree (depth=3)")
plt.show()

# Feature Importance of tree model
importances = clf.feature_importances_
importance_df = pd.DataFrame({'Feature': features, 'Importance': importances})
importance_df = importance_df.sort_values(by='Importance', ascending=True)

plt.figure(figsize=(12,6))
bars = plt.barh(importance_df['Feature'], importance_df['Importance'], color='skyblue')
plt.title("Feature Importance (Decision Tree)")
plt.xlabel("Importance")
plt.ylabel("Features")

# bar plot 
for bar in bars:
    width = bar.get_width()
    plt.text(width, bar.get_y() + bar.get_height()/2, f'{width:.2f}',
             va='center', ha='left', fontsize=10, color='black')

plt.tight_layout()
plt.show()

import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import (
    confusion_matrix,
    f1_score,
    accuracy_score,
    roc_curve,
    roc_auc_score,
    auc
)

y_pred_proba = clf.predict_proba(X_test)[:, 1]
y_pred = (y_pred_proba > 0.5).astype(int)

cm = confusion_matrix(y_test, y_pred)
TN, FP, FN, TP = cm.ravel()

# Sensitivity (Recall)와 Specificity 계산
sensitivity = TP / (TP + FN) if (TP + FN) > 0 else 0
specificity = TN / (TN + FP) if (TN + FP) > 0 else 0

# F1 Score, Accuracy, AUROC
f1 = f1_score(y_test, y_pred)
accuracy = accuracy_score(y_test, y_pred)
auroc = roc_auc_score(y_test, y_pred_proba)

# ROC curve
fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)
roc_auc = auc(fpr, tpr)

# AUROC의 95% CI using bootstraps
n_bootstraps = 1000
rng = np.random.RandomState(42)
bootstrapped_scores = []
for i in range(n_bootstraps):
    indices = rng.randint(0, len(y_test), len(y_test))
    if len(np.unique(y_test[indices])) < 2:
        continue
    score = roc_auc_score(y_test[indices], y_pred_proba[indices])
    bootstrapped_scores.append(score)

bootstrapped_scores = np.array(bootstrapped_scores)
bootstrapped_scores.sort()
ci_lower = bootstrapped_scores[int(0.025 * len(bootstrapped_scores))]
ci_upper = bootstrapped_scores[int(0.975 * len(bootstrapped_scores))]

print("Sensitivity (Recall): {:.4f}".format(sensitivity))
print("Specificity: {:.4f}".format(specificity))
print("F1 Score: {:.4f}".format(f1))
print("Accuracy: {:.4f}".format(accuracy))
print("AUROC: {:.4f}".format(auroc))
print("95% CI for AUROC: [{:.4f}, {:.4f}]".format(ci_lower, ci_upper))

plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='blue', label=f'ROC curve (AUC = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], color='gray', linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve for Decision Tree')
plt.legend(loc="lower right")
plt.show()
